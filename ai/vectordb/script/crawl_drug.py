#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì•½í’ˆ ì •ë³´ í¬ë¡¤ë§ ë° NBSP ë¬¸ì ìë™ ì •ë¦¬ í†µí•© ìŠ¤í¬ë¦½íŠ¸
í¬ë¡¤ë§ ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ NBSP ë¬¸ìë¥¼ ì¼ë°˜ ê³µë°±ìœ¼ë¡œ ë³€í™˜í•˜ê³  ë°±ì—… íŒŒì¼ì„ ì‚­ì œí•©ë‹ˆë‹¤.
"""

import requests
from bs4 import BeautifulSoup
import csv
import os
import json
import re
from pathlib import Path
import pandas as pd

def clean_text(text):
    """HTML íƒœê·¸ ë° íŠ¹ìˆ˜ ë¬¸ì ì •ë¦¬"""
    if not text:
        return ''
    
    # ê¸°ë³¸ì ì¸ HTML íƒœê·¸ ë³€í™˜
    text = text.replace('<br>', '\n').replace('&nbsp;', ' ').strip()
    
    # BeautifulSoupìœ¼ë¡œ ëª¨ë“  HTML íƒœê·¸ ì œê±°
    soup = BeautifulSoup(text, 'html.parser')
    clean_content = soup.get_text(separator=' ').strip()
    
    # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ì˜ ê³µë°±ìœ¼ë¡œ ì •ë¦¬
    clean_content = re.sub(r'\s+', ' ', clean_content)
    
    return clean_content

def parse_drug_name(original_name):
    """
    í’ˆëª©ëª…ì„ íŒŒì‹±í•˜ì—¬ í’ˆëª©ëª…ê³¼ ìš©ëŸ‰ìœ¼ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        original_name (str): ì›ë³¸ í’ˆëª©ëª…
    
    Returns:
        dict: {'í’ˆëª©ëª…': str, 'ìš©ëŸ‰': str}
    """
    if not original_name or pd.isna(original_name):
        return {'í’ˆëª©ëª…': '', 'ìš©ëŸ‰': ''}
    
    name = str(original_name).strip()
    
    # 1. "(ìˆ˜ì¶œìš©)" í¬í•¨ëœ ê²½ìš° ì›ë³¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if "(ìˆ˜ì¶œìš©)" in name:
        return {'í’ˆëª©ëª…': name, 'ìš©ëŸ‰': ''}
    
    # 2. ê´„í˜¸ë¥¼ ëª¨ë‘ ì œê±°í•œ ê¸°ë³¸ ì´ë¦„
    bracket_pattern = r'\([^)]*\)'
    base_name = re.sub(bracket_pattern, '', name).strip()
    
    # 3. ìš©ëŸ‰ ë‹¨ìœ„ íŒ¨í„´ ì •ì˜ (ê¸´ ë‹¨ìœ„ë¶€í„° ë¨¼ì € ë§¤ì¹­ë˜ë„ë¡ ì •ë ¬)
    dosage_units = [
        'ë§ˆì´í¬ë¡œê·¸ëŒ', 'ë§ˆì´í¬ë¡œê·¸ë¨',  # ë§ˆì´í¬ë¡œ ë‹¨ìœ„
        'ë°€ë¦¬ê·¸ëŒ', 'ë°€ë¦¬ê·¸ë¨', 'ë¯¸ë¦¬ê·¸ëŒ', 'ë°€ë¦¬ê·¸',  # ë°€ë¦¬ ë‹¨ìœ„ (í•œê¸€)
        'ê·¸ëŒ', 'ê·¸ë¨',  # ê·¸ë¨ ë‹¨ìœ„ (í•œê¸€)
        'mcg', 'Î¼g', 'mg', 'g',  # ì˜ë¬¸/ê¸°í˜¸ ë‹¨ìœ„
        'ML', 'ml', 'mL',  # ì•¡ì²´ ë‹¨ìœ„ ì¶”ê°€
        'IU', 'iu'  # êµ­ì œë‹¨ìœ„ ì¶”ê°€
    ]
    
    # ìš©ëŸ‰ íŒ¨í„´: ìˆ«ì(ì†Œìˆ˜ì , / í¬í•¨ ê°€ëŠ¥) + ë‹¨ìœ„
    # ì˜ˆ: 150ë°€ë¦¬ê·¸ë¨, 80/12.5ë°€ë¦¬ê·¸ë¨, 40mg ë“±
    dosage_pattern = r'([0-9]+(?:\.[0-9]+)?(?:/[0-9]+(?:\.[0-9]+)?)*)\s*(' + '|'.join(re.escape(unit) for unit in dosage_units) + r')'
    
    dosage_match = re.search(dosage_pattern, base_name, re.IGNORECASE)
    
    if dosage_match:
        # ìš©ëŸ‰ ì •ë³´ ì¶”ì¶œ
        dosage_value = dosage_match.group(1)
        dosage_unit = dosage_match.group(2)
        dosage = f"{dosage_value}{dosage_unit}"
        
        # ìš©ëŸ‰ ë¶€ë¶„ì„ ì œê±°í•œ ë‚˜ë¨¸ì§€ê°€ í’ˆëª©ëª…
        drug_name = base_name[:dosage_match.start()].strip()
        if not drug_name:  # í’ˆëª©ëª…ì´ ë¹„ì–´ìˆìœ¼ë©´ ì „ì²´ë¥¼ í’ˆëª©ëª…ìœ¼ë¡œ
            drug_name = base_name
            dosage = ""
    else:
        # ìš©ëŸ‰ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°
        drug_name = base_name
        dosage = ""
    
    return {
        'í’ˆëª©ëª…': drug_name,
        'ìš©ëŸ‰': dosage
    }

def crawl_drug_info(drug_cd):
    """ì•½í’ˆ ì •ë³´ í¬ë¡¤ë§"""
    url = f"https://www.health.kr/searchDrug/result_drug.asp?drug_cd={drug_cd}"
    ajax_url = f"https://www.health.kr/searchDrug/ajax/ajax_result_drug2.asp?drug_cd={drug_cd}"

    drug_name_text = ''
    ingredient_text = ''
    dur_text = ''
    medication_guide_text = ''
    try:
        # Fetch drug name and ingredient info from AJAX URL
        ajax_response = requests.get(ajax_url)
        ajax_response.raise_for_status()
        ajax_data = json.loads(ajax_response.text)
        if ajax_data and len(ajax_data) > 0:
            if 'drug_name' in ajax_data[0]:
                drug_name_text = ajax_data[0]['drug_name']
            if 'sunb' in ajax_data[0]:
                # sunb í•„ë“œì—ì„œ ì„±ë¶„ ì •ë³´ ì¶”ì¶œ ë° ì •ë¦¬
                raw_ingredient = ajax_data[0]['sunb']
                # HTML íƒœê·¸ ë° íŠ¹ìˆ˜ ë¬¸ì ì œê±°
                ingredient_text = clean_text(raw_ingredient.replace('@', '').replace('</a>', ''))
            
            # DUR ì •ë³´ ìˆ˜ì§‘
            dur_fields = ['dur_age', 'dur_contra', 'dur_preg', 'dur_senior', 'dur_dose', 'dur_period', 'dur_donate', 'dur_form']
            dur_info = []
            for field in dur_fields:
                if field in ajax_data[0] and ajax_data[0][field] and ajax_data[0][field].strip():
                    field_name = {
                        'dur_age': '[ì—°ë ¹ì£¼ì˜]',
                        'dur_contra': '[ê¸ˆê¸°]', 
                        'dur_preg': '[ì„ë¶€ì£¼ì˜]',
                        'dur_senior': '[ê³ ë ¹ìì£¼ì˜]',
                        'dur_dose': '[ìš©ëŸ‰ì£¼ì˜]',
                        'dur_period': '[íˆ¬ì—¬ê¸°ê°„ì£¼ì˜]',
                        'dur_donate': '[í—Œí˜ˆì£¼ì˜]',
                        'dur_form': '[ì œí˜•ì£¼ì˜]'
                    }.get(field, f'[{field}]')
                    # HTML íƒœê·¸ ì œê±° ë° í…ìŠ¤íŠ¸ ì •ë¦¬
                    cleaned_dur_text = clean_text(ajax_data[0][field])
                    dur_info.append(f"{field_name} {cleaned_dur_text}")
            
            dur_text = ', '.join(dur_info) if dur_info else ''
            
            # ë³µì•½ì •ë³´ ìˆ˜ì§‘ (mediguide í•„ë“œ)
            if 'mediguide' in ajax_data[0] and ajax_data[0]['mediguide']:
                medication_guide_text = clean_text(ajax_data[0]['mediguide'].replace('brbr', '\n').replace('<br>', '\n'))

        # Fetch main page content for other details
        response = requests.get(url)
        response.raise_for_status()
    except requests.exceptions.RequestException as e:
        print(f"Error fetching data for {drug_cd}: {e}")
        return None, None, None, None, None, None, None

    soup = BeautifulSoup(response.text, 'html.parser')

    effect = soup.find('div', id='tab_effect')
    dosage = soup.find('div', id='tab_dosage')
    caution = soup.find('div', id='tab_caution')

    effect_text = clean_text(str(effect)) if effect else ''
    dosage_text = clean_text(str(dosage)) if dosage else ''
    caution_text = clean_text(str(caution)) if caution else ''

    return drug_name_text, ingredient_text, dur_text, effect_text, dosage_text, caution_text, medication_guide_text

def fix_nbsp_in_csv(input_file, auto_cleanup=True):
    """
    CSV íŒŒì¼ì˜ NBSP ë¬¸ìë¥¼ ì¼ë°˜ ê³µë°±ìœ¼ë¡œ ë³€í™˜
    
    Args:
        input_file (str): ì…ë ¥ CSV íŒŒì¼ ê²½ë¡œ
        auto_cleanup (bool): ì„±ê³µ í›„ ë°±ì—… íŒŒì¼ ìë™ ì‚­ì œ ì—¬ë¶€
    
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    input_path = Path(input_file)
    
    if not input_path.exists():
        print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_file}")
        return False
    
    # ë°±ì—… íŒŒì¼ ìƒì„±
    backup_file = input_path.with_suffix('.bak')
    
    # ê¸°ì¡´ ë°±ì—… íŒŒì¼ì´ ìˆìœ¼ë©´ ì‚­ì œ
    if backup_file.exists():
        backup_file.unlink()
        print(f"ê¸°ì¡´ ë°±ì—… íŒŒì¼ ì‚­ì œ: {backup_file}")
    
    print(f"ë°±ì—… íŒŒì¼ ìƒì„±: {backup_file}")
    input_path.rename(backup_file)
    
    try:
        with open(backup_file, 'r', encoding='utf-8') as infile:
            content = infile.read()
        
        # NBSP ë¬¸ìë“¤ì„ ì¼ë°˜ ê³µë°±ìœ¼ë¡œ ë³€í™˜
        # \u00A0: Non-breaking space (UTF-8)
        # \u2007: Figure space
        # \u2008: Punctuation space
        # \u2009: Thin space
        # \u200A: Hair space
        # \u202F: Narrow no-break space
        # \u205F: Medium mathematical space
        content = re.sub(r'[\u00A0\u2007\u2008\u2009\u200A\u202F\u205F]', ' ', content)
        
        # ì—°ì†ëœ ê³µë°±ë“¤ì„ í•˜ë‚˜ì˜ ê³µë°±ìœ¼ë¡œ ì •ë¦¬
        content = re.sub(r' +', ' ', content)
        
        # ê° í•„ë“œì˜ ì•ë’¤ ê³µë°± ì œê±° (ë‹¨, CSV êµ¬ì¡° ìœ ì§€)
        lines = content.split('\n')
        cleaned_lines = []
        
        for line in lines:
            if line.strip():  # ë¹ˆ ì¤„ì´ ì•„ë‹Œ ê²½ìš°
                # CSV í•„ë“œ ë¶„ë¦¬ í›„ ê° í•„ë“œì˜ ì•ë’¤ ê³µë°± ì œê±°
                fields = []
                in_quotes = False
                current_field = ""
                
                for char in line:
                    if char == '"':
                        in_quotes = not in_quotes
                        current_field += char
                    elif char == ',' and not in_quotes:
                        fields.append(current_field.strip())
                        current_field = ""
                    else:
                        current_field += char
                
                # ë§ˆì§€ë§‰ í•„ë“œ ì¶”ê°€
                if current_field:
                    fields.append(current_field.strip())
                
                # í•„ë“œë“¤ì„ ë‹¤ì‹œ ì¡°í•©
                cleaned_line = ','.join(fields)
                cleaned_lines.append(cleaned_line)
        
        # íŒŒì¼ ì €ì¥
        with open(input_file, 'w', encoding='utf-8', newline='') as outfile:
            outfile.write('\n'.join(cleaned_lines))
        
        print(f"NBSP ë¬¸ì ë³€í™˜ ì™„ë£Œ: {input_file}")
        
        # ë°±ì—… íŒŒì¼ ìë™ ì‚­ì œ
        if auto_cleanup and backup_file.exists():
            try:
                backup_file.unlink()
                print(f"ë°±ì—… íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {backup_file}")
            except Exception as e:
                print(f"ë°±ì—… íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")
        
        return True
        
    except Exception as e:
        print(f"NBSP ë³€í™˜ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # ì˜¤ë¥˜ ì‹œ ì›ë³¸ íŒŒì¼ ë³µêµ¬
        if backup_file.exists():
            backup_file.rename(input_path)
            print(f"ì›ë³¸ íŒŒì¼ ë³µêµ¬ ì™„ë£Œ: {input_file}")
        return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    csv_file_path = '../data/medicine_detail_info.csv'
    temp_csv_file_path = '../data/medicine_detail_info_temp.csv'

    # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    print("=== ì•½í’ˆ ì •ë³´ í¬ë¡¤ë§ ìŠ¤í¬ë¦½íŠ¸ ===")
    print("ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”:")
    print("1. Enter/ë¹ˆ ì…ë ¥: ê¸°ì¡´ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° ê±´ë„ˆë›°ê¸° (ê¸°ë³¸ê°’)")
    print("2. 'overwrite' ë˜ëŠ” 'o': ê¸°ì¡´ ë°ì´í„°ê°€ ìˆì–´ë„ ê°•ì œë¡œ ë®ì–´ì“°ê¸°")
    print("3. 'force' ë˜ëŠ” 'f': ëª¨ë“  ë°ì´í„°ë¥¼ ê°•ì œë¡œ ìƒˆë¡œ í¬ë¡¤ë§")
    
    user_input = input("ì…ë ¥í•˜ì„¸ìš”: ").strip().lower()
    
    # ë®ì–´ì“°ê¸° ëª¨ë“œ ê²°ì •
    if user_input in ['overwrite', 'o']:
        overwrite_mode = 'overwrite'
        print("ğŸ”„ ë®ì–´ì“°ê¸° ëª¨ë“œ: ê¸°ì¡´ ë°ì´í„°ê°€ ìˆì–´ë„ ìƒˆë¡œ í¬ë¡¤ë§í•©ë‹ˆë‹¤.")
    elif user_input in ['force', 'f']:
        overwrite_mode = 'force'
        print("ğŸš€ ê°•ì œ ëª¨ë“œ: ëª¨ë“  ë°ì´í„°ë¥¼ ìƒˆë¡œ í¬ë¡¤ë§í•©ë‹ˆë‹¤.")
    else:
        overwrite_mode = 'skip'
        print("â­ï¸ ê±´ë„ˆë›°ê¸° ëª¨ë“œ: ê¸°ì¡´ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° ê±´ë„ˆëœë‹ˆë‹¤.")
    
    print()

    drug_cds = []
    existing_data = []

    # Read existing data and drug_cds from the CSV
    if os.path.exists(csv_file_path):
        with open(csv_file_path, 'r', encoding='utf-8', newline='') as infile:
            reader = csv.reader(infile)
            header = next(reader)  # Read header
            for row in reader:
                drug_cds.append(row[0])
                existing_data.append(row)
    else:
        print(f"Error: {csv_file_path} not found.")
        return

    print(f"ì´ {len(drug_cds)}ê°œì˜ ì•½í’ˆ ì½”ë“œë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

    # Prepare data for writing
    new_rows = []
    processed_count = 0
    skipped_count = 0
    
    for i, drug_cd in enumerate(drug_cds):
        # Ensure current_row has enough columns before processing (9 columns for medicine_detail_info.csv)
        current_row = existing_data[i] if i < len(existing_data) else [drug_cd]
        while len(current_row) < 9: # Ensure it has all 9 columns
            current_row.append('')

        # ê¸°ì¡´ ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ë° ëª¨ë“œì— ë”°ë¥¸ ì²˜ë¦¬
        data_exists = current_row[1]  # ì œí’ˆëª… (index 1)ì´ ìˆëŠ”ì§€ í™•ì¸
        
        if data_exists and overwrite_mode == 'skip':
            new_rows.append(current_row)
            print(f"[{i+1}/{len(drug_cds)}] Skipping {drug_cd}: Data already exists.")
            skipped_count += 1
            continue
        elif data_exists and overwrite_mode == 'overwrite':
            print(f"[{i+1}/{len(drug_cds)}] Overwriting {drug_cd}: Existing data will be replaced.")
        elif overwrite_mode == 'force':
            print(f"[{i+1}/{len(drug_cds)}] Force crawling {drug_cd}: All data will be refreshed.")
        else:
            print(f"[{i+1}/{len(drug_cds)}] Crawling new data for {drug_cd}: No existing data found.")

        drug_name, ingredient, dur_info, effect, dosage, caution, medication_guide = crawl_drug_info(drug_cd)
        
        if drug_name:
            # ì œí’ˆëª… íŒŒì‹±í•˜ì—¬ ì œí’ˆëª…ê³¼ ìš©ëŸ‰ ë¶„ë¦¬
            parsed_name = parse_drug_name(drug_name)
            parsed_drug_name = parsed_name['í’ˆëª©ëª…']
            parsed_dosage = parsed_name['ìš©ëŸ‰']
            
            # Update the specific columns
            # ì»¬ëŸ¼ ë§¤í•‘: 0=ê³ ìœ ì½”ë“œ, 1=ì œí’ˆëª…, 2=ì„±ë¶„, 3=ìš©ëŸ‰, 4=ì˜ì•½í’ˆì•ˆì •ì„±ì •ë³´(DUR), 5=íš¨ëŠ¥ë°íš¨ê³¼, 6=ìš©ë²•ë°ìš©ëŸ‰, 7=ì‚¬ìš©ìƒì˜ì£¼ì˜ì‚¬í•­, 8=ë³µì•½ì •ë³´
            current_row[1] = parsed_drug_name  # ì œí’ˆëª… (íŒŒì‹±ëœ ê¹¨ë—í•œ ì´ë¦„)
            current_row[2] = ingredient        # ì„±ë¶„
            current_row[3] = parsed_dosage     # ìš©ëŸ‰ (íŒŒì‹±í•´ì„œ ì¶”ì¶œëœ ìš©ëŸ‰)
            current_row[4] = dur_info          # ì˜ì•½í’ˆì•ˆì •ì„±ì •ë³´(DUR)
            current_row[5] = effect            # íš¨ëŠ¥ë°íš¨ê³¼
            current_row[6] = dosage            # ìš©ë²•ë°ìš©ëŸ‰
            current_row[7] = caution           # ì‚¬ìš©ìƒì˜ì£¼ì˜ì‚¬í•­
            current_row[8] = medication_guide  # ë³µì•½ì •ë³´
            processed_count += 1
            print(f"[OK] Successfully crawled: {parsed_drug_name} - {ingredient}")
            if parsed_dosage:
                print(f"     ìš©ëŸ‰: {parsed_dosage}")
            if dur_info:
                print(f"     DUR: {dur_info[:100]}..." if len(dur_info) > 100 else f"     DUR: {dur_info}")
            if medication_guide:
                print(f"     ë³µì•½ì •ë³´: {medication_guide[:100]}..." if len(medication_guide) > 100 else f"     ë³µì•½ì •ë³´: {medication_guide}")
        else:
            print(f"[FAIL] Failed to crawl data for: {drug_cd}")
        
        new_rows.append(current_row)

    # Write all data (header + new_rows) to a temporary CSV file
    with open(temp_csv_file_path, 'w', encoding='utf-8', newline='') as outfile:
        writer = csv.writer(outfile)
        writer.writerow(header)
        writer.writerows(new_rows)

    # Replace the original CSV file with the temporary one
    os.replace(temp_csv_file_path, csv_file_path)
    
    print(f"\n=== í¬ë¡¤ë§ ì™„ë£Œ ===")
    print(f"ì²˜ë¦¬ëœ ì•½í’ˆ: {processed_count}ê°œ")
    print(f"ê±´ë„ˆë›´ ì•½í’ˆ: {skipped_count}ê°œ")
    print(f"ë°ì´í„°ê°€ {csv_file_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # í¬ë¡¤ë§ ì™„ë£Œ í›„ NBSP ë¬¸ì ìë™ ì •ë¦¬
    print(f"\n=== NBSP ë¬¸ì ìë™ ì •ë¦¬ ì‹œì‘ ===")
    if fix_nbsp_in_csv(csv_file_path):
        print("[SUCCESS] ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print("[ERROR] NBSP ì •ë¦¬ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        print("í¬ë¡¤ë§ì€ ì •ìƒì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìœ¼ë‚˜, ìˆ˜ë™ìœ¼ë¡œ fix_nbsp.pyë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()